-----------------------------------------------------------
FASE 1. Estructura base del proyecto y prueba de ejecucion
-----------------------------------------------------------
OBJETIVO

Crear la arquitectura minima para un MLP con capas abstractas, sin implementacion aun.
Esta fase verifica que:
    - El proyecto compile correctamente.
    - Las clases se instancian y se recorren.
    - El flujo forward() y backward() funciona con capas dummy.

ESTRUCTURA DE LAS CARPETAS

MLP_base/
├── include/
│   ├── layer.h
│   ├── mlp.h
│   └── profiler.h
├── src/
│   ├── mlp.cpp
│   └── profiler.cpp
├── main.cpp
├── Makefile
└── README

-----------------------------------------------------------
FASE 2. Implementacion de la clase Linear como subclase de Layer
-----------------------------------------------------------
OBJETIVO

Implementar una capa Linear que herede de Layer, con:
    - Metodos forward_cpu, backward_cpu
    - Metodos forward_gpu, backward_gpu
    - Inicializacion de pesos y sesgos
    - Documentacion detallada por clase, metodo y variable
    - Prueba de ejecucion y verificacion funcional

-----------------------------------------------------------
FASE 3. Inicializacion Estandarizada de Pesos y Sesgos
-----------------------------------------------------------
OBJETIVO

Implemenar metodos de inicializacion de parametros en la clase Lienar,
siguiendo practicas comunes en Deep Learning para mejorar la estabilidad
del entrenamiento. Se mantiene la co

FUNDAMENTO TEORICO

La inicializacion adecuada de pesos evita problemas como:
    - Exploding Gradients: Cuando los valores crecen exponencialmente
    - Vanishing Gradients: Cuando los valores se reducen a cero

Metodo Recomendados:
    - Xavier (Glorot): Activaciones lineales o tanh
    - He (Kaiming): Activaciones ReLU

-----------------------------------------------------------
FASE 4.
-----------------------------------------------------------
